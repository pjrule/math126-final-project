{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97441f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as la\n",
    "from typing import Tuple\n",
    "from time import time\n",
    "from numpy.linalg import inv\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a56e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PQLU = Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed068f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_lu(A: np.ndarray, k: int, l: int, seed: int=0) -> PQLU:\n",
    "    \"\"\"Performs a randomized rank-k LU decomposition of A.\n",
    "\n",
    "    Args:\n",
    "        A: An mXn matrix to decompose.\n",
    "        k: Rank of the decomposition.\n",
    "        l: Number of columns to use in the random matrix.\n",
    "        seed: Random seed.\n",
    "\n",
    "    Returns:\n",
    "        A 4-tuple containing P, Q, L, U.\"\"\"\n",
    "    rand = np.random.RandomState(seed)\n",
    "    # 1. Create a matrix G of size n × l whose entries are i.i.d. Gaussian\n",
    "    # random variables with zero mean and unit standard deviation.\n",
    "    assert l >= k\n",
    "    m, n = A.shape\n",
    "    G = rand.randn(n, l)\n",
    "\n",
    "    # 2. Y ← AG.    \n",
    "    Y = A @ G  \n",
    "    assert Y.shape == (m, l)\n",
    "\n",
    "    # 3. Apply RRLU decomposition (Theorem 3.1) to Y such that P Y Qy = LyUy.\n",
    "    #\n",
    "    # Remark 4.2. In practice, it is sufficient to perform step 3 in Algorithm\n",
    "    # 4.1 using standard LU decomposition with partial pivoting instead of\n",
    "    # applying RRLU. The cases where U grows exponentially are extremely rare...\n",
    "    P, L_y, U_y = la.lu(Y)\n",
    "    P = P.T\n",
    "    Q_y = np.identity(l) # TODO: replace with RRLU\n",
    "    assert P.shape == (m, m)\n",
    "    assert L_y.shape == (m, l)\n",
    "    assert U_y.shape == (l, l)\n",
    "    #assert np.allclose(P @ Y, L_y @ U_y)\n",
    "    #assert np.allclose(P @ Y @ Q_y, L_y @ U_y)\n",
    "\n",
    "    # 4. Truncate Ly and Uy by choosing the first k columns and the first k rows,\n",
    "    # respectively, such that Ly ← Ly(:, 1 : k) and Uy ← Uy(1 : k, :).\n",
    "    L_y = L_y[:, :k]\n",
    "    U_y = U_y[:k, :]\n",
    "    assert L_y.shape == (m, k) \n",
    "    assert U_y.shape == (k, l)\n",
    "\n",
    "    # 5. B ← (L_y †) PA\n",
    "    L_y_pseudoinverse = la.pinv(L_y)\n",
    "    assert L_y_pseudoinverse.shape == (k, m)\n",
    "    B = L_y_pseudoinverse @ P @ A\n",
    "    assert B.shape == (k, n)\n",
    "\n",
    "    # 6. Apply LU decomposition to B with column pivoting BQ = L_b U_b.\n",
    "    Q, U_b, L_b = la.lu(B.T)\n",
    "    #Q = Q.T\n",
    "    L_b = L_b.T\n",
    "    U_b = U_b.T\n",
    "    assert Q.shape == (n, n)\n",
    "    assert L_b.shape == (k, k)\n",
    "    assert U_b.shape == (k, n)\n",
    "    #assert np.allclose(B @ Q, L_b @ U_b)\n",
    "\n",
    "    # 7. L ← L_y L_b.\n",
    "    L = L_y @ L_b\n",
    "    assert L.shape == (m, k)\n",
    "\n",
    "    return P, Q, L, U_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d1167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9426305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split data into 50% train and 50% test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.5, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cda6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import pinv, norm\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class DictLearner(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def dist(self, x: np.ndarray, D: np.ndarray) -> float:\n",
    "        \"\"\"Calculates the distance metric between an input\n",
    "           vector x and a dictionary D\n",
    "\n",
    "        Args:\n",
    "            x: The input vector.\n",
    "            D: A trained dictionary.\n",
    "\n",
    "        Returns:\n",
    "            The distance between x and D.\"\"\"\n",
    "#         print(D.shape)\n",
    "#         print(pinv(D).shape)\n",
    "#         print(x.shape)\n",
    "\n",
    "        \n",
    "        return norm((D @ pinv(D))[:x.shape[0],:x.shape[0]] * x - x) ## WTH - dimensions don't align\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predicts which class the input vector x belongs to\n",
    "           given a list of dictionaries\n",
    "\n",
    "        Args:\n",
    "            X: Matrix of input vectors to classify\n",
    "\n",
    "        Returns:\n",
    "            The predicted class of each vector in X.\"\"\"\n",
    "        \n",
    "        \n",
    "        class_predictions = [self.classes[np.argmin([self.dist(x, self.dictionaries[class_]) for class_ in self.classes])] \n",
    "                             for x in X]\n",
    "        return class_predictions\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, k: dict = {}) -> list:\n",
    "        \"\"\"Trains a dictionary of size k for each dataset in X\n",
    "\n",
    "        Args:\n",
    "            X: A matrix of input vectors.\n",
    "            y: A vector of class labels.\n",
    "            k: A map for the size of each class's dictionary. (key,val) = (class, size)\n",
    "\n",
    "        Returns:\n",
    "            A DictLearner object with a trained dictionary for each class\"\"\"\n",
    "        \n",
    "        self.dictionaries = dict()\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        for class_ in self.classes:\n",
    "            X_class = X[np.where(y == class_)[0]]\n",
    "            P, Q, L, U = randomized_lu(X_class, k[class_], k[class_] + 5)\n",
    "#             print(P.T.shape, L.shape)\n",
    "            self.dictionaries[class_] = P.T @ L\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f6e245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictLearner()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = DictLearner()\n",
    "k = dict.fromkeys(np.unique(y_train), 64) # magic number 64 is size of each dictionary\n",
    "\n",
    "dic.fit(X_train, y_train, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16607e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 5, 1, 0, 6, 1, 5, 1, 6]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.predict(X_train[:10]) # supposed to be 0...9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32aa81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13251670378619154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52330cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1468298109010011"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d734398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e6d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_env",
   "language": "python",
   "name": "basic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
